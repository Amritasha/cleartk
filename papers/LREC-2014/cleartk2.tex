\documentclass[10pt, a4paper]{article}
\usepackage{lrec2006}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{microtype}

\newcommand{\code}[1]{\texttt{\small #1}}

\title{ClearTK 2.0:\\ Lessons learned developing a machine learning framework for UIMA}

\name{Steven Bethard$^1$, Philip Ogren$^2$, Lee Becker$^3$}

\address{%
$^1$University of Alabama at Birmingham, Birmingham, AL, USA, \texttt{bethard@cis.uab.edu}\\
$^2$Oracle America, Broomfield, CO, USA, \texttt{philip@ogren.info}\\
$^3$Hapara Inc., Boulder, CO, USA \texttt{lee@leebecker.com}
}

\hyphenation{Annotation-Handler Classifier-Annotator Chunker-Feature-Extractor}

\abstract{}


\begin{document}

\maketitleabstract

\section{Introduction}
The Unstructured Information Management Architecture (UIMA) framework for developing natural language processing pipelines grew in popularity since it was open-sourced by IBM in 2005.
The framework gained recognition recently for being the underlying architecture of the IBM Watson system that defeated human champions in the game show Jeopardy! \cite{ferrucci_building_2010}.
However, the framework only establishes an architecture for plugging together processing components.
Within the components, there is no support for standard patterns like constructing machine learning classifiers based on sets of features.

The ClearTK framework was introduced to address this gap \cite{ogren-etal:2008:UIMA-LREC,ogren-etal:2009:UIMA-GSCL} by providing:
\begin{itemize}
\item A common interface and wrappers for popular machine learning libraries such as SVMlight, LIBSVM, OpenNLP MaxEnt, and Mallet.
\item A rich feature extraction library that can be used with any of the machine learning classifiers. Under the covers, ClearTK understands each of the native machine learning libraries and translates features into a format appropriate to whatever model is being used.
\item Infrastructure for using and evaluating machine learning classifiers within the UIMA framework.
\end{itemize}

Since its inception in 2008, ClearTK has undergone a large number of changes based on feedback from users and developers.
In this paper, we reflect on key lessons learned over the last 5 years, and how they reflect generally on the development of natural language processing frameworks.

\section{Annotators should look like annotators}
At the core of UIMA is the idea of an annotator, which provides a \code{process(JCas)} method that inspects the document (\code{JCas}), performs some analysis, and adds annotations representing the result of that analysis to the \code{JCas}.
This is a concept familiar even to novice UIMA users, and there are analogs in other frameworks, e.g. Stanford CoreNLP's \code{CoreMap}\footnote{http://nlp.stanford.edu/software/corenlp.shtml} and GATE's \code{Document}\footnote{http://gate.ac.uk/ie/}.

In the first versions of ClearTK, a machine-learning-based UIMA annotator would create an \code{AnnotationHandler}, which performed feature extraction and passed the features back to the annotator.
This reduced boilerplate by unifying feature extraction for training classifiers and making predictions.
However, there was a significant drawback to this approach:
the callback-like nature of \code{AnnotationHandler} was very unlike the \code{process(JCas)} method familiar to UIMA users, and was therefore hard for many users to understand.
In ClearTK 0.5, we replaced the \code{AnnotationHandler} callback with a \code{ClassifierAnnotator} that had the standard \code{process(JCas)} method but required a bit more code to handle the differences between training and prediction.
User feedback confirmed that the benefit of maintaining a familiar annotator interface far outweighed the cost of writing a bit more code.

% this is similar to the above; could be cut if we need space
We learned a similar lesson in designing an API for Begin-Inside-Outside (BIO) style chunking classification.
Our original chunker framework defined a chunker as a subtype of \code{ClassifierAnnotator} that split labels into BIO tags on tokens and then delegated to a \code{ChunkerFeatureExtractor} where the user would write code to extract the token-level features.
This delegation had the problem again that the \code{ChunkerFeatureExtractor} interface was not the standard \code{process(JCas)} method, so there was a fairly high barrier to entry.
In ClearTK 1.2 we replaced this architecture with a set of utility objects for converting chunk labels into token labels (and vice versa) that could be used directly in a standard annotator with a standard \code{process(JCas)} method.
Removing the delegation again allowed our users to leverage their knowledge or UIMA annotators when working with ClearTK.

% Features like TF-IDF are in the Annotator, not in the encoder
% I decided to skip this; is seemed too complicated to explain 

\section{Pipelines should look like pipelines}

(Is it that pipelines should look like pipelines or is it that tightly coupled operations should be left together?)

Though most deployed natural language processing systems follow a linear flow (e.g. tokenization, POS-tagging, parsing, \ldots), many tasks require multiple passes through the data.  Common examples of these multi-pass scenarios include model training and evaluation as well as feature normalization.  In developing ClearTK components for more complex flows, we have opted to stucture these abstractions at the granularity of the pipeline.  This in turn makes the programmer's job easier by organizing around an already familiar construct, and reduces the barrier to adoption of new frameworks.

\subsection{Model Training and Evaluation}
Consider the case of model training and evaluation.  Someone writing an evaluation for a new NLP component is best served by thinking of this in terms of three tasks:

\begin{enumerate}
\item Creation of CollectionReaders to read a subset of the corpus
\item Training a model given a CollectionReader
\item Testing a model given a CollectionReader
\end{enumerate}


This abstraction preserves relationships between tightly coupled operations, while providing the programmer with the freedom to make each task as simple or complex as necessary.  If preprocessing is needed it is simply added to to the training and testing methods.  Even multipass situations like semi-supervised models are permitted with this abstraction.  Most importantly, an existing pipeline can be dropped in place into the evaluation framework without need for refactoring or alteration.

\textbf{(HELP!!!: I need a way to contrast this with other approaches without dragging everyone into discussion about pipeline providers)}

% this is probably not necessary
\lstinputlisting[language=Java]{eval.java}

\subsection{Feature Transformation}

Feature normalization is a common prerequisite for many machine learning algorithms.  For information retrieval tasks it is common to scale term counts by inverse document frequency or to transform it into a z-score (zero mean, unit standard deviation).

At its core feature transformation consists of:
\begin{enumerate}
\item Extracting features
\item Identifying features in need of transformation
\item Computing sufficient statistics for transformation
\item Transforming the features
\end{enumerate}

When dealing solely with a dataset, these steps are simply a matter of selecting and transforming column values.  However, in processing and pipeline oriented environments, this is not possible.  One workaround to this limitation involves extracting the statistics independently of the pipeline, and then configuring analysis engines to accept these statistics as parameters for scaling during feature extraction.

It has been our experience that this decoupling is error prone and leads to long-term maintenance issues, especially when dealing with ever changing corpora or evaluation parameters.  Although there is no way to avoid performing feature scaling in two passes, the ClearTK approach makes feature transformation more accessible by making it interoperable with the existing ClearTK extraction, training, and classification operations.

To facilitate this, ClearTK introduces the \emph{TransformableFeatures} and \emph{TrainableFeatureExtractors} and {\emph InstanceDataWriter} classes.  Like all other feature extractors in ClearTK, a TrainableFeaturesExtractor accepts a JCas and an Annotation and returns a list of features.  In practice most TrainableFeatureExtractors delegate extraction to a sub-extractor, and instead of returning standard features it returns a list of TransformableFeatures.  ClearTK includes TrainableFeatureExtractors for common transformations such as z-score, tf*idf, min-max normalization and cosine similarity.

Typically when training a CleartkAnnotator, the extracted feature vectors are written directly to a data file for consumption by the learning algorithm.  When using TrainableFeatureExtractors, the feature vectors are instead serialized using the InstanceDataWriter.  This enables the TrainableFeatureExtractors to iterate over the instances as a collection and compute the necessary statistics for direct transformation.

After training each TrainableFeatureExtractor, the TransformableFeatures within the instances are transformed and then written out to the data file for training of the classifier.
During classification, TrainableFeatureExtractors load a configuration file and directly transform the features for use by the classifier.

\textbf{Struggling to succinctly wrap this up}.  This approach to feature scaling provides a means of wrangling a complex process into the paradigms already employed by users of ClearTK and UIMAFit.


\section{CollectionReaders should be minimal}

While CollectionReaders often serve a critical role in populating the UIMA CAS with the text, annotations and data necessary for processing, they are tedious to write, and they are not well suited for more scalable environments like UIMA-AS.  They are also not well suited for corpora where annotations are distributed across multiple documents such as OntoNotes.

As we have developed more support in ClearTK for importing various corpora, we have found that role of CollectionReaders should be minimal as possible.  Instead of creating a CollectionReader for each corpus, we have pushed the work of parsing data formats and reading files to Annotators while making use of the lighter-weight URICollectionReader.  The URICollectionReader does nothing more than populate the CAS's URI view with a Uniform Resource Identifier (URI).  

Perhaps the simplest example of an Annotator as a reader is the UriToDocumentTextAnnotor. It simply reads the URI from the CAS's URI view and populates the target view with contents of the document pointed to by the URI.  In more complex cases, the URI may point to an XML or JSON configuration file or even to byte offsets within a file.  This decoupling of CollectionReader and import even allows for easier processing of collections of mixed document type as Annotators can choose to process only the views relevant to the them.

Beyond the added flexibility, the most compelling reason for minimizing the use of CollectionReaders comes down to implementation time.  We have found users of ClearTK are more adept at creating custom Annotators than CollectionReaders, as the Annotator convention of overriding the process() method is well understood.


\section{Modules should group classes by function}
not organized by type system

cleartk-type-system

cleartk-corpus

cleartk-feature


\section{Type-system-agnostic requires interfaces}

Philip's blog post

weaknesses of OpenNLP approach (e.g., assumes pos is an attribute of token)

ClearNLP work


\section{Users need help past the UIMA overhead}
After the many improvements to ClearTK interfaces and usability over the years, we've now reached a point where much of the overhead of learning ClearTK is actually the overhead of learning UIMA.
To understand the UIMA framework, you need to understand not just how to write an annotator with a \code{process(JCas)} method -- which is what's really at the heart of the framework -- but also how to:
\begin{itemize}
\item Declare a type system that describes the annotations you want your annotator to create
\item Configure your build system to generate Java classes from the type system
\item Create code to read your training data into \code{JCas} objects
\item Declare (using XML files or Java annotations) any parameters needed to initialize your annotator
\item Create an \code{AnalysisEngine} object from your annotator and the initialization parameters
\item \ldots
\end{itemize}
These tasks are fairly easy for a UIMA expert, but are often challenging and overwhelming for a new UIMA user.
Thus, to get new potential users of ClearTK up to speed, we've found that it can be quite helpful to have a UIMA expert put the above items together.
Then, the new users can focus on the core problems that ClearTK is designed for: extracting features and using the classifier in the \code{process(JCas)} method of the annotator.
We applied exactly this approach with new users of ClearTK, and successfully developed both a student response analysis system for SemEval-2013 \cite{okoye-bethard-sumner:2013:SemEval-2013}, and a relation extraction system for Apache cTAKES \cite{dligach2013discovering}.

\section{Discussion}

\bibliographystyle{lrec2006}
\bibliography{cleartk2}

\end{document}

